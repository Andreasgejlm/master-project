{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CfE6fdS9Z-3E",
    "outputId": "1ce168d9-48fe-4b61-8bb2-592cddfc8da7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from tensorflow.keras import Model, Input, layers, optimizers, utils, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from PIL import Image, ImageDraw\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "ZyuOOqMNZ-3E"
   },
   "outputs": [],
   "source": [
    "class CGH_Model:\n",
    "    def __init__(self, num_data, slm_info, num_z_planes, z_sep, focal_length, wavelength):\n",
    "        # Inputs\n",
    "        # num_data:        Number of sets to train the newwork on\n",
    "        # slm_info:        Tuple (int, int, float, float, float) containing \n",
    "        #                  (slm resolution x, slm resolution y, slm pixel pitch)\n",
    "        # num_z_planes:    Number of separated planes around the focal plane. MUST BE UNEVEN.\n",
    "        # z_sep:           Distance between separated planes.\n",
    "        # focal_length:    Focal length, or, the distance to the center plane.\n",
    "        # wavelength:      wavelength used in the system [nm].\n",
    "        \n",
    "        self.path = os.getcwd()\n",
    "        self.training_data_path = os.path.join(os.getcwd(), \"training_data/\")\n",
    "        self.validation_data_path = os.path.join(os.getcwd(), \"validation_data/\")\n",
    " \n",
    "        \n",
    "        self.nT = num_data\n",
    "        self.nV = int(num_data * 0.125)\n",
    "        self.Mx = slm_info[0]\n",
    "        self.My = slm_info[1]\n",
    "        self.lp = slm_info[2]\n",
    "        self.l0x = self.Mx * self.lp\n",
    "        self.l0y = self.My * self.lp\n",
    "        self.nz = num_z_planes\n",
    "        self.dz = z_sep\n",
    "        self.f = focal_length\n",
    "        self.wl = wavelength*10**-9\n",
    "        self.batch_size = 32\n",
    "        self.IF = 8\n",
    "        \n",
    "        self.epochs = 3\n",
    "        \n",
    "        self._calculate_phase_factors()\n",
    "    \n",
    "    def set_batch_size(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def set_epochs(self, epochs):\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def get_sample(self):\n",
    "        return self.training_data[0:31]\n",
    "        \n",
    "    def print_model_summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "\n",
    "# TRAINING AND VALIDATION DATA\n",
    "    def _create_lines(self, N_images):\n",
    "        line_images = np.zeros((N_images, self.Mx, self.My, self.nz))\n",
    "        for image in line_images:\n",
    "            for plane in range(self.nz):\n",
    "                im = Image.fromarray(image[:, :, plane])\n",
    "                draw_im = ImageDraw.Draw(im)\n",
    "                num_lines = random.randint(0, 10)\n",
    "                for n_line in range(num_lines):\n",
    "                    start_x = random.randint(10, self.Mx-10)\n",
    "                    start_y = random.randint(10, self.My-10)\n",
    "                    stop_x = random.randint(10, self.Mx-10)\n",
    "                    stop_y = random.randint(10, self.My-10)\n",
    "                    draw_im.line((start_x, start_y, stop_x, stop_y), fill=random.randint(128, 256), width=random.randint(1, 3))\n",
    "                image[:,:,plane] = np.array(im)\n",
    "        return line_images\n",
    "    \n",
    "    def _create_circles(self, N_images):\n",
    "        circle_images = np.zeros((N_images, self.Mx, self.My, self.nz))\n",
    "        for image in circle_images:\n",
    "            for plane in range(self.nz):\n",
    "                im = Image.fromarray(image[:, :, plane])\n",
    "                draw_im = ImageDraw.Draw(im)\n",
    "                num_circles = random.randint(0, 10)\n",
    "                for n_circle in range(num_circles):\n",
    "                    diameter = random.randint(2, int(self.Mx / 4))\n",
    "                    x_0 = random.randint(diameter, self.Mx-diameter)\n",
    "                    y_0 = random.randint(diameter, self.My-diameter)\n",
    "                    x_1 = x_0 + diameter\n",
    "                    y_1 = y_0 + diameter\n",
    "                    draw_im.ellipse([(x_0, y_0), (x_1, y_1)], outline = random.randint(0, 256), fill=random.randint(0, 256), width=random.randint(1, 3))\n",
    "                image[:,:,plane] = np.array(im)\n",
    "        return circle_images\n",
    "    \n",
    "    def _create_polygons(self, N_images):\n",
    "        poly_images = np.zeros((N_images, self.Mx, self.My, self.nz))\n",
    "        for image in poly_images:\n",
    "            for plane in range(self.nz):\n",
    "                im = Image.fromarray(image[:, :, plane])\n",
    "                draw_im = ImageDraw.Draw(im)\n",
    "                num_polys = random.randint(0, 10)\n",
    "                for n_poly in range(num_polys):\n",
    "                    radius = random.randint(10, int(self.Mx / 4))\n",
    "                    x_0 = random.randint(radius, self.Mx-radius)\n",
    "                    y_0 = random.randint(radius, self.My-radius)\n",
    "                    n_sides = random.randint(3, 6)\n",
    "                    xs = [random.randint(x_0-radius, x_0 + radius) for n in range(n_sides)]\n",
    "                    ys = [random.randint(y_0-radius, y_0 + radius) for n in range(n_sides)]\n",
    "                    xy = [val for pair in zip(xs, ys) for val in pair]\n",
    "                    draw_im.polygon(xy, outline = random.randint(0, 256), fill=random.randint(0, 256))\n",
    "                image[:,:,plane] = np.array(im)\n",
    "        return poly_images\n",
    "\n",
    "    \n",
    "    def _generate_training_data(self, n_lines=0.5, n_circles=0.25, n_polys=0.25):\n",
    "        assert n_lines + n_circles + n_polys == 1, \"Training data split should add up to 1\"\n",
    "        nL = int(n_lines * self.nT)\n",
    "        nC = int(n_circles * self.nT)\n",
    "        nP = int(n_polys * self.nT)\n",
    "        \n",
    "        # Check whether training dataset exists already\n",
    "        file_name = \"TRAIN-Mx{}-My{}-nz{}-nT{}-nV{}-nL{}-nC{}-nP{}.tfrecords\".format(self.Mx, self.My, self.nz, self.nT, self.nV, nL, nC, nP)\n",
    "        if os.path.exists(os.path.join(self.training_data_path, file_name)):\n",
    "            print( \"Chosen training data already exists. Continuing...\" )\n",
    "            self._generate_validation_data(n_lines, n_circles, n_polys)\n",
    "            return\n",
    "        else:\n",
    "            print(\"Generating training data...\")\n",
    "        \n",
    "        lines = self._create_lines(nL)\n",
    "        circles = self._create_circles(nC)\n",
    "        polys = self._create_polygons(nP)\n",
    "        training_data = np.concatenate((lines, circles, polys))\n",
    "        np.random.shuffle(training_data)\n",
    "        \n",
    "        with tf.io.TFRecordWriter(os.path.join(self.training_data_path, file_name)) as writer:\n",
    "            for training_image in tqdm(training_data):\n",
    "                image_bytes = training_image.tostring()\n",
    "                \n",
    "                f = tf.train.Feature(bytes_list = tf.train.BytesList(value = [image_bytes]))\n",
    "                \n",
    "                feature = {'image': f}\n",
    "                    \n",
    "                features = tf.train.Features(feature = feature)\n",
    "                example = tf.train.Example(features = features)\n",
    "                example_to_string = example.SerializeToString()\n",
    "                    \n",
    "                writer.write(example_to_string)\n",
    "            \n",
    "        print(\"Finished generating training data\")\n",
    "        self._generate_validation_data(n_lines, n_circles, n_polys)\n",
    "    \n",
    "    def _generate_validation_data(self, n_lines, n_circles, n_polys):\n",
    "        assert n_lines + n_circles + n_polys == 1, \"Training data split should add up to 1\"\n",
    "        nL = int(n_lines * self.nV)\n",
    "        nC = int(n_circles * self.nV)\n",
    "        nP = int(n_polys * self.nV)\n",
    "        \n",
    "        # Check whether validation dataset exists already\n",
    "        file_name = \"VAL-Mx{}-My{}-nz{}-nT{}-nV{}-nL{}-nC{}-nP{}.tfrecords\".format(self.Mx, self.My, self.nz, self.nT, self.nV, nL, nC, nP)\n",
    "        if os.path.exists(os.path.join(self.validation_data_path, file_name)):\n",
    "            print( \"Chosen validation data already exists. Continuing...\" )\n",
    "            return\n",
    "        else:\n",
    "            print(\"Generating validation data...\")\n",
    "        \n",
    "        lines = self._create_lines(nL)\n",
    "        circles = self._create_circles(nC)\n",
    "        polys = self._create_polygons(nP)\n",
    "        validation_data = np.concatenate((lines, circles, polys))\n",
    "        np.random.shuffle(validation_data)\n",
    "        \n",
    "        with tf.io.TFRecordWriter(os.path.join(self.validation_data_path, file_name)) as writer:\n",
    "            for val_image in tqdm(validation_data):\n",
    "                image_bytes = val_image.tostring()\n",
    "                \n",
    "                f = tf.train.Feature(bytes_list = tf.train.BytesList(value = [image_bytes]))\n",
    "                \n",
    "                feature = {'image': f}\n",
    "                    \n",
    "                features = tf.train.Features(feature = feature)\n",
    "                example = tf.train.Example(features = features)\n",
    "                example_to_string = example.SerializeToString()\n",
    "                    \n",
    "                writer.write(example_to_string)\n",
    "        print(\"Finished generating validation data\")\n",
    "\n",
    "# FOURIER OPTICS SPECIFIC FUNCTIONS\n",
    "    def _calculate_phase_factors(self):\n",
    "        fx = np.linspace(-self.Mx / 2 + 1, self.Mx / 2, self.Mx) * 1 / (self.lp * self.Mx)\n",
    "        fy = np.linspace(-self.My / 2 + 1, self.My / 2, self.My) * 1 / (self.lp * self.My)\n",
    "        Fx, Fy = np.meshgrid(fx, fy)\n",
    "        \n",
    "        center = self.nz // 2\n",
    "        phase_factors = []\n",
    "\n",
    "        for n in range(self.nz):\n",
    "            zn = n - center\n",
    "            p = np.exp(-1j * math.pi * self.wl * (zn * self.dz) * (Fx ** 2 + Fy ** 2))\n",
    "            phase_factors.append(p.astype(np.complex64))\n",
    "        self.phase_factors = phase_factors\n",
    "\n",
    "    def _prop_to_slm(self, inputs):\n",
    "        # We need to propagate the input backwards to the SLM with ifft2\n",
    "        real, imag = inputs\n",
    "        field_z0 = tf.complex(tf.squeeze(real), 0.) * tf.exp(tf.complex(0., tf.squeeze(imag)))   \n",
    "        shift = tf.signal.fftshift(field_z0, axes=[1,2])\n",
    "        slm = tf.math.angle(tf.signal.ifftshift(tf.signal.ifft2d(shift)))\n",
    "        return tf.expand_dims(slm, axis=-1)\n",
    "\n",
    "    def _prop_to_planes(self, slm_phase):\n",
    "        # Then propagate to the z planes we have defined\n",
    "        phi_slm = tf.complex(np.float32(0.), tf.squeeze(slm_phase))\n",
    "        phi_slm = tf.math.exp(phi_slm)\n",
    "\n",
    "        output_list = []\n",
    "        for factor in self.phase_factors:\n",
    "            phased_slm_layer = tf.multiply(phi_slm, factor)\n",
    "            fft = tf.signal.fftshift(tf.signal.fft2d(phased_slm_layer))\n",
    "            I = tf.cast(tf.math.square(tf.math.abs(fft)), tf.float32)\n",
    "            output_list.append(tf.squeeze(I))\n",
    "        return tf.stack(output_list, axis=3)\n",
    "\n",
    " # LAYERS   \n",
    "\n",
    "    def _cc_layer(self, n_feature_maps, input):\n",
    "      x = layers.Conv2D(n_feature_maps, (3, 3), activation='relu', padding='same')(input)\n",
    "      x = layers.Conv2D(n_feature_maps, (3, 3), activation='relu', padding='same')(x)\n",
    "      return x\n",
    "    \n",
    "    def _cbn_layer(self, n_feature_maps, input):\n",
    "      x = layers.Conv2D(n_feature_maps, (3, 3), activation='relu', padding='same')(input)\n",
    "      x = layers.BatchNormalization()(x)\n",
    "      x = layers.Conv2D(n_feature_maps, (3, 3), activation='relu', padding='same')(x)\n",
    "      x = layers.BatchNormalization()(x)\n",
    "      return x\n",
    "\n",
    "    def _interleave(self, input):\n",
    "        return tf.nn.space_to_depth(input = input, block_size = self.IF)\n",
    "\n",
    "    def _deinterleave(self, input):\n",
    "      return tf.nn.depth_to_space(input = input, block_size = self.IF)\n",
    "\n",
    "    def _shallow_Unet(self, input_layer):\n",
    "        x1 = self._cbn_layer(64, input_layer)\n",
    "        x = layers.MaxPooling2D((2, 2))(x1)\n",
    "        x2 = self._cbn_layer(128, x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x2)\n",
    "        x = self._cc_layer(256, x)\n",
    "        x = layers.UpSampling2D()(x)\n",
    "        concat2 = layers.Concatenate()([x2, x])  \n",
    "        x = self._cc_layer(128, concat2)\n",
    "        x = layers.UpSampling2D()(x)\n",
    "        concat1 = layers.Concatenate()([x1, x])  \n",
    "        x = self._cc_layer(64, concat1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _branching(self, previous, before_unet):\n",
    "        real_branch = self._cc_layer(64, previous)\n",
    "        real_branch = layers.concatenate([real_branch, before_unet])\n",
    "        real_branch = self._cc_layer(self.IF**2, real_branch)\n",
    "        imag_branch = self._cc_layer(64, previous)\n",
    "        imag_branch = layers.concatenate([imag_branch, before_unet])\n",
    "        imag_branch = self._cc_layer(self.IF**2, imag_branch)\n",
    "        de_int_real = layers.Lambda(self._deinterleave, name=\"De-interleave_real\")(real_branch)\n",
    "        de_int_imag = layers.Lambda(self._deinterleave, name=\"De-interleave_imag\")(imag_branch)\n",
    "        \n",
    "        slm_phase = layers.Lambda(self._prop_to_slm, name=\"SLM_phase\")([de_int_real, de_int_imag])\n",
    "        \n",
    "        return slm_phase\n",
    "    \n",
    "    def _prop_layer(self, previous):\n",
    "        return layers.Lambda(self.prop_to_planes, name=\"z-planes\")(previous)\n",
    "    \n",
    "# ABSTRACTIONS\n",
    "\n",
    "    def _loss_func(self, y_true, y_pred):\n",
    "        \n",
    "        y_predict = self._prop_to_planes(y_pred)\n",
    "        \n",
    "        num = tf.reduce_sum(y_predict * y_true, axis=[1, 2, 3])\n",
    "        denom = tf.sqrt(tf.reduce_sum(tf.pow(y_predict, 2), axis=[1, 2, 3])*tf.reduce_sum(tf.pow(y_true, 2), axis=[1, 2, 3]))\n",
    "        return 1 - tf.reduce_mean((num + 1) / (denom + 1), axis=0)\n",
    "\n",
    "    def create_model(self):\n",
    "        train_in = Input((self.Mx, self.My, self.nz,), name='Input', batch_size=self.batch_size)\n",
    "        interleaved = layers.Lambda(self._interleave, name='Interleave')(train_in)\n",
    "        unet = self._shallow_Unet(interleaved)\n",
    "        slm_phi = self._branching(unet, interleaved)\n",
    "        self.model = Model(train_in, slm_phi)\n",
    "        self.model.compile(optimizer=optimizers.Adam(), loss=self._loss_func, metrics=['acc'])\n",
    "    \n",
    "    def train(self):\n",
    "      savefile = \"/content/drive/MyDrive/Speciale/Private/ML/Beamscanner-ml-jupyter/nz{}-M{}x{}-b{}-e{}-{}\".format(self.nz, self.Mx, self.My, self.batch_size, self.epochs, datetime.datetime.now())\n",
    "      savefile = savefile + \"-unet_2level_w_concat\" + \".csv\"\n",
    "      csv_logger = callbacks.CSVLogger(savefile, append=True)\n",
    "      self.model.fit(self.training_data, self.training_data, epochs=self.epochs, batch_size=self.batch_size, validation_data=(self.validation_data, self.validation_data), callbacks=[csv_logger])\n",
    "        \n",
    "    def predict(self, planes):\n",
    "        phi_slm = self.model.predict(planes)\n",
    "        _z_planes = self._prop_to_planes(phi_slm)\n",
    "        \n",
    "        z_planes = _z_planes.numpy()\n",
    "        \n",
    "        print(\"Creating subplots\")\n",
    "        p = np.array(planes)\n",
    "        \n",
    "        fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "        \n",
    "        axs[0,1].imshow(p[0, :, :, 0], cmap='gray', interpolation='none')\n",
    "        axs[0,1].set_title('Desired z=-dz')\n",
    "\n",
    "        axs[0,2].imshow(p[0, :, :, 1], cmap='gray', interpolation='none')\n",
    "        axs[0,2].set_title('Desired z=0')\n",
    "\n",
    "        axs[0,3].imshow(p[0, :, :, 2], cmap='gray', interpolation='none')\n",
    "        axs[0,3].set_title('Desired z=dz')\n",
    "        \n",
    "        axs[1,0].imshow(phi_slm[0, :, :, 0], cmap='gray', interpolation='none')\n",
    "        axs[1,0].set_title('Generated phase pattern')\n",
    "        \n",
    "        axs[1,1].imshow(z_planes[0, :, :, 0], cmap='gray', interpolation='none')\n",
    "        axs[1,1].set_title('Predicted z=-dz')\n",
    "\n",
    "        axs[1,2].imshow(z_planes[0, :, :, 1], cmap='gray', interpolation='none')\n",
    "        axs[1,2].set_title('Predicted z=0')\n",
    "\n",
    "        axs[1,3].imshow(z_planes[0, :, :, 2], cmap='gray', interpolation='none')\n",
    "        axs[1,3].set_title('Predicted z=dz')\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5vCMgBQbZ-3E",
    "outputId": "405abff7-58d4-4b11-86fa-f8a67b54b88c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:03<00:00, 258.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 179.72it/s]\n"
     ]
    }
   ],
   "source": [
    "cgh = CGH_Model(1024, (256, 256, 3.90625*10**-5), 3, 0.02, 0.5, 532)\n",
    "\n",
    "cgh.set_batch_size(32)\n",
    "cgh.set_epochs(20)\n",
    "\n",
    "cgh._generate_training_data()\n",
    "\n",
    "cgh.create_model()\n",
    "\n",
    "#cgh.print_model_summary()\n",
    "\n",
    "#gt = cgh.get_sample()\n",
    "\n",
    "#cgh.predict(gt)\n",
    "\n",
    "#cgh.train()\n",
    "\n",
    "#cgh.predict(gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uehKI4DiZ-3F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Beamscanner-tf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CGH-ml",
   "language": "python",
   "name": "cgh-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
